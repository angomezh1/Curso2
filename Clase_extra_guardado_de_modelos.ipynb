{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Calse_extra_guardado_de_modelos.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/angomezh1/Curso2/blob/master/Clase_extra_guardado_de_modelos.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gMmz659LYFjq",
        "colab_type": "text"
      },
      "source": [
        "<p><img alt=\"Colaboratory logo\" height=\"140px\" src=\"https://upload.wikimedia.org/wikipedia/commons/archive/f/fb/20161010213812%21Escudo-UdeA.svg\" align=\"left\" hspace=\"10px\" vspace=\"0px\"></p>\n",
        "\n",
        "<h1> Diplomado de Análisis de datos y Machine Learning en Python</h1>\n",
        "\n",
        "\n",
        "El presente diplomado hace parte del centro de Big Data de la facultad de ciencias exactas y naturales (FCEN) de la Universidad de Antioquia."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aOiMjs8aro28",
        "colab_type": "code",
        "outputId": "2c9a5036-ad96-4c56-de4c-5158007e11d9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "%tensorflow_version 2.x"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow 2.x selected.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gNWV9ssAru0K",
        "colab_type": "code",
        "outputId": "27d6c22a-3f79-42e6-904d-7809815d49d9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        }
      },
      "source": [
        "!pip install h5py"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: h5py in /tensorflow-2.0.0/python3.6 (2.10.0)\n",
            "Requirement already satisfied: six in /tensorflow-2.0.0/python3.6 (from h5py) (1.13.0)\n",
            "Requirement already satisfied: numpy>=1.7 in /tensorflow-2.0.0/python3.6 (from h5py) (1.17.4)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "od_SBy7asQ4u",
        "colab_type": "code",
        "outputId": "561dc274-e36e-4827-cbf7-cb70e4d45ff1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 237
        }
      },
      "source": [
        "!wget https://raw.githubusercontent.com/jbrownlee/Datasets/master/pima-indians-diabetes.data.csv"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-12-12 23:42:57--  https://raw.githubusercontent.com/jbrownlee/Datasets/master/pima-indians-diabetes.data.csv\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 23278 (23K) [text/plain]\n",
            "Saving to: ‘pima-indians-diabetes.data.csv’\n",
            "\n",
            "\r          pima-indi   0%[                    ]       0  --.-KB/s               \rpima-indians-diabet 100%[===================>]  22.73K  --.-KB/s    in 0.007s  \n",
            "\n",
            "2019-12-12 23:42:58 (3.29 MB/s) - ‘pima-indians-diabetes.data.csv’ saved [23278/23278]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U7zkVzO1YY7j",
        "colab_type": "text"
      },
      "source": [
        "Cuando estamos creando modelos de deep learning  estámos calculando una serie de pesos $w$ que ajusten lo mejor posible (dependiendo de nuestra arquitectura, funciones de perdida y optimizadores) una serie de datos.\n",
        "\n",
        "Dichos modelos serán usados de manera posterior como parte de algún proceso más complejo. Si tuvieramos que entrenar un modelo cada que lo deseamos usar o cada que reiniciamos la aplicación sería intratable; los modelos reales pueden tomar horas, incluso semanas o meses en ser entrenados, por tanto necesitamos una forma de guardar nuestros pesos y la información de nuestra arquitectura para ser usada de manera posterior."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3OtUN9p9sUaa",
        "colab_type": "text"
      },
      "source": [
        "# Guardar el modelo en un JSON"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i4n-MVmWsYvY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.models import model_from_json\n",
        "import numpy\n",
        "import os\n",
        "\n",
        "numpy.random.seed(7)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zpX-M1Fls3Vf",
        "colab_type": "code",
        "outputId": "b0bc9ecc-9d58-44e7-e92d-f80f7a28c067",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "!ls"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "pima-indians-diabetes.data.csv\tsample_data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QysFRqXjstya",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dataset = numpy.loadtxt(\"./pima-indians-diabetes.data.csv\", delimiter=\",\")\n",
        "\n",
        "X = dataset[:,0:8]\n",
        "Y = dataset[:,8]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oqzL2Eh1sw_Y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = Sequential()\n",
        "model.add(Dense(12, input_dim=8, activation='relu'))\n",
        "model.add(Dense(8, activation='relu'))\n",
        "model.add(Dense(1, activation='sigmoid'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BvZkIWx2s-UZ",
        "colab_type": "code",
        "outputId": "136c1d60-0e25-4e2e-e50b-786963c200d6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        }
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense (Dense)                (None, 12)                108       \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 8)                 104       \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 1)                 9         \n",
            "=================================================================\n",
            "Total params: 221\n",
            "Trainable params: 221\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eI537QJptAcH",
        "colab_type": "code",
        "outputId": "7c27f0cf-d628-44d5-abfe-a3023a7c2d6c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "model.fit(X, Y, epochs=150, batch_size=10, verbose=0)\n",
        "scores = model.evaluate(X, Y, verbose=0)\n",
        "print(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "accuracy: 76.82%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0sWOaZNMtEBn",
        "colab_type": "code",
        "outputId": "65b79f42-cb9e-4a1b-db31-6ba5290ec8b1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "#guardamos la arquitectura en un archivo json\n",
        "model_json = model.to_json()\n",
        "with open(\"model.json\", \"w\") as json_file:\n",
        "    json_file.write(model_json)\n",
        "#guardamos los pesos en un archivo h5\n",
        "model.save_weights(\"model.h5\")\n",
        "print(\"Saved model to disk\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Saved model to disk\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Ltdx9lMt17r",
        "colab_type": "code",
        "outputId": "68f14fe5-27f5-4864-8b72-02f6d845ab68",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "!ls"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "model.h5  model.json  pima-indians-diabetes.data.csv  sample_data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lGKKAnHat2_L",
        "colab_type": "code",
        "outputId": "63c277f9-9156-47d7-d0a8-fbe06dd34911",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "#cargamos la arquitectura\n",
        "json_file = open('model.json', 'r')\n",
        "loaded_model_json = json_file.read()\n",
        "json_file.close()\n",
        "loaded_model = model_from_json(loaded_model_json)\n",
        "#cargamos los pesos\n",
        "loaded_model.load_weights(\"model.h5\")\n",
        "print(\"Loaded model from disk\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loaded model from disk\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YSblm2out7cL",
        "colab_type": "code",
        "outputId": "fcf31f4b-f589-4686-ffb3-41a2eff02b14",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "#recompilamos el modelo\n",
        "loaded_model.compile(loss='binary_crossentropy', optimizer='rmsprop', metrics=['accuracy'])\n",
        "score = loaded_model.evaluate(X, Y, verbose=0)\n",
        "print(\"%s: %.2f%%\" % (loaded_model.metrics_names[1], score[1]*100))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "accuracy: 76.82%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cisu8L9zt9R_",
        "colab_type": "code",
        "outputId": "89468844-cfbc-42a3-9bf5-ccdbd4f8b9c5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        }
      },
      "source": [
        "!cat model.json"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{\"class_name\": \"Sequential\", \"config\": {\"name\": \"sequential\", \"layers\": [{\"class_name\": \"Dense\", \"config\": {\"name\": \"dense\", \"trainable\": true, \"batch_input_shape\": [null, 8], \"dtype\": \"float32\", \"units\": 12, \"activation\": \"relu\", \"use_bias\": true, \"kernel_initializer\": {\"class_name\": \"GlorotUniform\", \"config\": {\"seed\": null}}, \"bias_initializer\": {\"class_name\": \"Zeros\", \"config\": {}}, \"kernel_regularizer\": null, \"bias_regularizer\": null, \"activity_regularizer\": null, \"kernel_constraint\": null, \"bias_constraint\": null}}, {\"class_name\": \"Dense\", \"config\": {\"name\": \"dense_1\", \"trainable\": true, \"dtype\": \"float32\", \"units\": 8, \"activation\": \"relu\", \"use_bias\": true, \"kernel_initializer\": {\"class_name\": \"GlorotUniform\", \"config\": {\"seed\": null}}, \"bias_initializer\": {\"class_name\": \"Zeros\", \"config\": {}}, \"kernel_regularizer\": null, \"bias_regularizer\": null, \"activity_regularizer\": null, \"kernel_constraint\": null, \"bias_constraint\": null}}, {\"class_name\": \"Dense\", \"config\": {\"name\": \"dense_2\", \"trainable\": true, \"dtype\": \"float32\", \"units\": 1, \"activation\": \"sigmoid\", \"use_bias\": true, \"kernel_initializer\": {\"class_name\": \"GlorotUniform\", \"config\": {\"seed\": null}}, \"bias_initializer\": {\"class_name\": \"Zeros\", \"config\": {}}, \"kernel_regularizer\": null, \"bias_regularizer\": null, \"activity_regularizer\": null, \"kernel_constraint\": null, \"bias_constraint\": null}}]}, \"keras_version\": \"2.2.4-tf\", \"backend\": \"tensorflow\"}"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xrcWoXhRZyBA",
        "colab_type": "text"
      },
      "source": [
        "Como vemos, hemos guardado por separado los pesos de los datos que definen la arquitectura.\n",
        "En éste caso es necesario recompilar, y para ello saber cuales fueron las funciones de perdida, los optimizadores y las metricas usadas en el modelo al ser guardado en disco."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bHuDEp-NuDq5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "57eTmU37yVeR",
        "colab_type": "text"
      },
      "source": [
        "# Guardar el modelo en un YAML"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZTvLhmfGaOnL",
        "colab_type": "text"
      },
      "source": [
        "También nos es posible guardar la arquitectura en un archivo YAML, el cual es parecido a un archivo JSON pero separado por lineas."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YyTPrKUQyXYy",
        "colab_type": "code",
        "outputId": "02678f46-cb53-4c23-fcd6-40e64333e1c5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "!pip install PyYAML"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.6/dist-packages (3.13)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a7sQMH1kyaPQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.models import model_from_yaml"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7D20xRw2yeak",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model2 = Sequential()\n",
        "model2.add(Dense(12, input_dim=8, activation='relu'))\n",
        "model2.add(Dense(8, activation='relu'))\n",
        "model2.add(Dense(1, activation='sigmoid'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AFxPqozkyjmO",
        "colab_type": "code",
        "outputId": "3dbb6c4c-ad21-4700-85bb-ba502063dc53",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        }
      },
      "source": [
        "model2.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_3 (Dense)              (None, 12)                108       \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 8)                 104       \n",
            "_________________________________________________________________\n",
            "dense_5 (Dense)              (None, 1)                 9         \n",
            "=================================================================\n",
            "Total params: 221\n",
            "Trainable params: 221\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Aa0fxAbIymRc",
        "colab_type": "code",
        "outputId": "826b9f01-848a-44b1-af8c-0058d22b5cbd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "model2.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "model2.fit(X, Y, epochs=150, batch_size=10, verbose=0)\n",
        "\n",
        "scores = model2.evaluate(X, Y, verbose=0)\n",
        "print(\"%s: %.2f%%\" % (model2.metrics_names[1], scores[1]*100))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "accuracy: 76.69%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3GR3JDP-ypjj",
        "colab_type": "code",
        "outputId": "e065d25b-b9e5-4c50-b1fa-fe39377c4e67",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "#guardamos la arquitectura en un archivo YAML\n",
        "model_yaml = model2.to_yaml()\n",
        "with open(\"model2.yaml\", \"w\") as yaml_file:\n",
        "    yaml_file.write(model_yaml)\n",
        "#guardamos los pesos en un archivo h5\n",
        "model2.save_weights(\"model2.h5\")\n",
        "print(\"Saved model to disk\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Saved model to disk\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5icrYeVvi7xW",
        "colab_type": "code",
        "outputId": "42641344-69a2-44eb-e5e1-8c53576eda1c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "!ls"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "model2.h5    model.h5\t pima-indians-diabetes.data.csv\n",
            "model2.yaml  model.json  sample_data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "42BSNaqlyyjh",
        "colab_type": "code",
        "outputId": "c469fdad-b72a-49ec-ec20-7a57d14932fa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "#cargamos la arquitectura\n",
        "yaml_file = open('model2.yaml', 'r')\n",
        "loaded_model_yaml = yaml_file.read()\n",
        "yaml_file.close()\n",
        "loaded_model = model_from_yaml(loaded_model_yaml)\n",
        "#cargamos los pesos\n",
        "loaded_model.load_weights(\"model2.h5\")\n",
        "print(\"Loaded model from disk\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loaded model from disk\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gl4uuX1Ny3AC",
        "colab_type": "code",
        "outputId": "a8768728-c259-4fb1-b9ce-7be2ae608633",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "#recompilamos el modelo\n",
        "loaded_model.compile(loss='binary_crossentropy', optimizer='rmsprop', metrics=['accuracy'])\n",
        "score = loaded_model.evaluate(X, Y, verbose=0)\n",
        "print(\"%s: %.2f%%\" % (loaded_model.metrics_names[1], score[1]*100))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "accuracy: 76.69%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tHlf4Ntfj0-4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import files"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ixo0qle3j4wK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "files.download('model2.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2BFsL3bSy6kB",
        "colab_type": "code",
        "outputId": "8eb3596b-20fb-4826-de77-f26c1c536de7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "!cat model2.yaml"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "backend: tensorflow\n",
            "class_name: Sequential\n",
            "config:\n",
            "  layers:\n",
            "  - class_name: Dense\n",
            "    config:\n",
            "      activation: relu\n",
            "      activity_regularizer: null\n",
            "      batch_input_shape: !!python/tuple [null, 8]\n",
            "      bias_constraint: null\n",
            "      bias_initializer:\n",
            "        class_name: Zeros\n",
            "        config: {}\n",
            "      bias_regularizer: null\n",
            "      dtype: float32\n",
            "      kernel_constraint: null\n",
            "      kernel_initializer:\n",
            "        class_name: GlorotUniform\n",
            "        config: {seed: null}\n",
            "      kernel_regularizer: null\n",
            "      name: dense_3\n",
            "      trainable: true\n",
            "      units: 12\n",
            "      use_bias: true\n",
            "  - class_name: Dense\n",
            "    config:\n",
            "      activation: relu\n",
            "      activity_regularizer: null\n",
            "      bias_constraint: null\n",
            "      bias_initializer:\n",
            "        class_name: Zeros\n",
            "        config: {}\n",
            "      bias_regularizer: null\n",
            "      dtype: float32\n",
            "      kernel_constraint: null\n",
            "      kernel_initializer:\n",
            "        class_name: GlorotUniform\n",
            "        config: {seed: null}\n",
            "      kernel_regularizer: null\n",
            "      name: dense_4\n",
            "      trainable: true\n",
            "      units: 8\n",
            "      use_bias: true\n",
            "  - class_name: Dense\n",
            "    config:\n",
            "      activation: sigmoid\n",
            "      activity_regularizer: null\n",
            "      bias_constraint: null\n",
            "      bias_initializer:\n",
            "        class_name: Zeros\n",
            "        config: {}\n",
            "      bias_regularizer: null\n",
            "      dtype: float32\n",
            "      kernel_constraint: null\n",
            "      kernel_initializer:\n",
            "        class_name: GlorotUniform\n",
            "        config: {seed: null}\n",
            "      kernel_regularizer: null\n",
            "      name: dense_5\n",
            "      trainable: true\n",
            "      units: 1\n",
            "      use_bias: true\n",
            "  name: sequential_1\n",
            "keras_version: 2.2.4-tf\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lpiWdgRjarrV",
        "colab_type": "text"
      },
      "source": [
        "De igual forma nos es necesario conocer los detalles del modelado (función de perdida, optimizador y metricas usadas) para poder recompilar el modelo, pero hecho ésto el modelo es exactamente el mismo que el que se tenía al momento de guardado."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cz4Grwxsy-7-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f6n6vf-XzC_j",
        "colab_type": "text"
      },
      "source": [
        "# Guardar el modelo y los pesos en un mismo archivo"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "64MTXIQza-Oq",
        "colab_type": "text"
      },
      "source": [
        "Si deseamos guardar toda la información del modelado en el mismo archivo (incluidas las funciones de perdida, optimización y metrica), como suele suceder, podemos hacerlo en un solo archivo h5."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u63GVpAHzGqu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model3 = Sequential()\n",
        "model3.add(Dense(12, input_dim=8, activation='relu'))\n",
        "model3.add(Dense(8, activation='relu'))\n",
        "model3.add(Dense(1, activation='sigmoid'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cdMlVW-VzP4w",
        "colab_type": "code",
        "outputId": "7cfa54ee-c020-4c75-de4b-9252240586d5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        }
      },
      "source": [
        "model3.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_6 (Dense)              (None, 12)                108       \n",
            "_________________________________________________________________\n",
            "dense_7 (Dense)              (None, 8)                 104       \n",
            "_________________________________________________________________\n",
            "dense_8 (Dense)              (None, 1)                 9         \n",
            "=================================================================\n",
            "Total params: 221\n",
            "Trainable params: 221\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-T2MovvhzRrB",
        "colab_type": "code",
        "outputId": "369af2ca-3a22-44cb-ce70-d8b5b939b935",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "model3.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "model3.fit(X, Y, epochs=150, batch_size=10, verbose=0)\n",
        "scores = model3.evaluate(X, Y, verbose=0)\n",
        "print(\"%s: %.2f%%\" % (model3.metrics_names[1], scores[1]*100))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "accuracy: 76.56%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cl74-paAzX-f",
        "colab_type": "code",
        "outputId": "a2d7a985-13be-4629-f40e-d9272bc4ce5f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "#guardamos todos los datos del modelado juntos\n",
        "model3.save(\"model3.h5\")\n",
        "print(\"Saved model to disk\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Saved model to disk\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BxLzZ2k_zgMa",
        "colab_type": "code",
        "outputId": "3cedee52-fc62-405c-aa09-761ea22a64db",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "!ls"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "model2.h5    model3.h5\tmodel.json\t\t\tsample_data\n",
            "model2.yaml  model.h5\tpima-indians-diabetes.data.csv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BUzPuVypziPq",
        "colab_type": "text"
      },
      "source": [
        "# Cargar un modelo completo desde el disco"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vq-tuXc6zlPs",
        "colab_type": "code",
        "outputId": "f4afa001-5e6c-4ab8-b6e7-9c2090e7643b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        }
      },
      "source": [
        "from tensorflow.keras.models import load_model\n",
        "model4 = load_model('model3.h5')\n",
        "model4.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_6 (Dense)              (None, 12)                108       \n",
            "_________________________________________________________________\n",
            "dense_7 (Dense)              (None, 8)                 104       \n",
            "_________________________________________________________________\n",
            "dense_8 (Dense)              (None, 1)                 9         \n",
            "=================================================================\n",
            "Total params: 221\n",
            "Trainable params: 221\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K1_GWZWkzwnb",
        "colab_type": "code",
        "outputId": "288bd3c8-2406-4b74-edd3-95d0db5c914a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "score = model4.evaluate(X, Y, verbose=0)\n",
        "print(\"%s: %.2f%%\" % (model4.metrics_names[1], score[1]*100))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "accuracy: 76.56%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ShHg8_YSbZYl",
        "colab_type": "text"
      },
      "source": [
        "Note que en éste caso no es necesario el recompilado del modelo, pues el archivo h5 contiene toda la información necesaria al ser cargado en memoria."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ifixV5pdz-VI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SlFgocGz0JLz",
        "colab_type": "text"
      },
      "source": [
        "#Continuar el entrenamiento de manera posterior"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-QYgRlZ_bjgn",
        "colab_type": "text"
      },
      "source": [
        "Al ser tan costoso el entrenamiento del modelo, o incluso al ser posible hacer transfer learning con finetuning, nos es posible cargar un modelo desde disco (con cualquiera de los métodos anteriores) y continuar entrenandolo con nuevos datos o por más épocas."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BUr9k7cf0NV6",
        "colab_type": "code",
        "outputId": "7ccccfbd-3867-4e02-c388-4047143c1232",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 417
        }
      },
      "source": [
        "model4.fit(X, Y, epochs=10, batch_size=10)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 768 samples\n",
            "Epoch 1/10\n",
            "768/768 [==============================] - 0s 519us/sample - loss: 0.5034 - accuracy: 0.7695\n",
            "Epoch 2/10\n",
            "768/768 [==============================] - 0s 259us/sample - loss: 0.4910 - accuracy: 0.7695\n",
            "Epoch 3/10\n",
            "768/768 [==============================] - 0s 269us/sample - loss: 0.4923 - accuracy: 0.7630\n",
            "Epoch 4/10\n",
            "768/768 [==============================] - 0s 277us/sample - loss: 0.4870 - accuracy: 0.7773\n",
            "Epoch 5/10\n",
            "768/768 [==============================] - 0s 262us/sample - loss: 0.4925 - accuracy: 0.7630\n",
            "Epoch 6/10\n",
            "768/768 [==============================] - 0s 265us/sample - loss: 0.4873 - accuracy: 0.7591\n",
            "Epoch 7/10\n",
            "768/768 [==============================] - 0s 293us/sample - loss: 0.4908 - accuracy: 0.7839\n",
            "Epoch 8/10\n",
            "768/768 [==============================] - 0s 287us/sample - loss: 0.4814 - accuracy: 0.7812\n",
            "Epoch 9/10\n",
            "768/768 [==============================] - 0s 261us/sample - loss: 0.4870 - accuracy: 0.7630\n",
            "Epoch 10/10\n",
            "768/768 [==============================] - 0s 277us/sample - loss: 0.4855 - accuracy: 0.7643\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fbe405f62b0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pKfaOYDR0WzT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XBr6fnNa0cwa",
        "colab_type": "text"
      },
      "source": [
        "#Guardar el modelo cada cierto tiempo (epoch)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3ARBappKb5Hv",
        "colab_type": "text"
      },
      "source": [
        "Nos es posible incluso guardar modelos que están siendo entrenados en etápas intermedias, ésto para probar su evolución o con intereses investigativos.\n",
        "\n",
        "Ésto lo podemos hacer con los `callbacks`, al igual que hacemos el `earlystoping`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pT0j7Jmj0hw9",
        "colab_type": "code",
        "outputId": "cd335fea-1680-4548-916f-02f72db88af5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        }
      },
      "source": [
        "model5 = Sequential()\n",
        "model5.add(Dense(12, input_dim=8, activation='relu'))\n",
        "model5.add(Dense(8, activation='relu'))\n",
        "model5.add(Dense(1, activation='sigmoid'))\n",
        "model5.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_9 (Dense)              (None, 12)                108       \n",
            "_________________________________________________________________\n",
            "dense_10 (Dense)             (None, 8)                 104       \n",
            "_________________________________________________________________\n",
            "dense_11 (Dense)             (None, 1)                 9         \n",
            "=================================================================\n",
            "Total params: 221\n",
            "Trainable params: 221\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PQisAo9m0zF8",
        "colab_type": "code",
        "outputId": "c8415ee2-25c0-4215-dc9f-bcf282b4d46e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        }
      },
      "source": [
        "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
        "\n",
        "model_checkpoint = ModelCheckpoint('modelo5-{epoch:02d}.h5', period=2,save_weights_only=False)\n",
        "early_stopping = EarlyStopping(patience=3, restore_best_weights=True)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of samples seen.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tAYOtZJ0mMBa",
        "colab_type": "code",
        "outputId": "ba04e8ef-af92-468a-8bba-81eefa069411",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "!ls"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "model2.h5    model3.h5\tmodel.json\t\t\tsample_data\n",
            "model2.yaml  model.h5\tpima-indians-diabetes.data.csv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T7zZbUcj1BbJ",
        "colab_type": "code",
        "outputId": "61e0921d-dcc9-408b-b880-c853783604be",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 619
        }
      },
      "source": [
        "model5.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "model5.fit(X, Y, epochs=10, batch_size=10, callbacks=[model_checkpoint, early_stopping]) \n",
        "#note que podemos incluir en el arreglo de callbacks cuantos funciones de callback queramos"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 768 samples\n",
            "Epoch 1/10\n",
            "580/768 [=====================>........] - ETA: 0s - loss: 6.4275 - accuracy: 0.4966WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
            "768/768 [==============================] - 1s 899us/sample - loss: 5.8826 - accuracy: 0.4740\n",
            "Epoch 2/10\n",
            "750/768 [============================>.] - ETA: 0s - loss: 2.3873 - accuracy: 0.4387WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
            "768/768 [==============================] - 0s 305us/sample - loss: 2.3641 - accuracy: 0.4362\n",
            "Epoch 3/10\n",
            "590/768 [======================>.......] - ETA: 0s - loss: 1.3435 - accuracy: 0.4610WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
            "768/768 [==============================] - 0s 265us/sample - loss: 1.2968 - accuracy: 0.4518\n",
            "Epoch 4/10\n",
            "600/768 [======================>.......] - ETA: 0s - loss: 0.9988 - accuracy: 0.5050WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
            "768/768 [==============================] - 0s 288us/sample - loss: 0.9624 - accuracy: 0.4974\n",
            "Epoch 5/10\n",
            "730/768 [===========================>..] - ETA: 0s - loss: 0.8638 - accuracy: 0.5740WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
            "768/768 [==============================] - 0s 294us/sample - loss: 0.8545 - accuracy: 0.5742\n",
            "Epoch 6/10\n",
            "630/768 [=======================>......] - ETA: 0s - loss: 0.7668 - accuracy: 0.6222WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
            "768/768 [==============================] - 0s 282us/sample - loss: 0.7608 - accuracy: 0.6159\n",
            "Epoch 7/10\n",
            "600/768 [======================>.......] - ETA: 0s - loss: 0.6954 - accuracy: 0.6417WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
            "768/768 [==============================] - 0s 268us/sample - loss: 0.7107 - accuracy: 0.6484\n",
            "Epoch 8/10\n",
            "590/768 [======================>.......] - ETA: 0s - loss: 0.7079 - accuracy: 0.6339WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
            "768/768 [==============================] - 0s 284us/sample - loss: 0.7011 - accuracy: 0.6315\n",
            "Epoch 9/10\n",
            "760/768 [============================>.] - ETA: 0s - loss: 0.6761 - accuracy: 0.6513WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
            "768/768 [==============================] - 0s 281us/sample - loss: 0.6712 - accuracy: 0.6549\n",
            "Epoch 10/10\n",
            "610/768 [======================>.......] - ETA: 0s - loss: 0.6476 - accuracy: 0.6738WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
            "768/768 [==============================] - 0s 276us/sample - loss: 0.6551 - accuracy: 0.6693\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fbe3fa68f28>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4LVVqllG1OsI",
        "colab_type": "code",
        "outputId": "bee8996a-b57c-4908-c202-5cdc3715089f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        }
      },
      "source": [
        "!ls"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "model2.h5    model.h5\t    modelo5-04.h5  modelo5-10.h5\n",
            "model2.yaml  model.json     modelo5-06.h5  pima-indians-diabetes.data.csv\n",
            "model3.h5    modelo5-02.h5  modelo5-08.h5  sample_data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ENmZXr6t1eZX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}